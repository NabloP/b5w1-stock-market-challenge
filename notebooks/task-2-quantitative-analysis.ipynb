{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0429a764",
   "metadata": {},
   "source": [
    "# üß† Task 2 ‚Äì Quantitative Sentiment‚ÄìPrice Analysis  \n",
    "üìò Version: 2025-06-01  \n",
    "\n",
    "This notebook initiates exploratory and quantitative analysis of stock price movements in relation to sentiment signals extracted from financial news.  \n",
    "It supports the computation of technical indicators, return alignment, and visual diagnostics.\n",
    "\n",
    "---\n",
    "\n",
    "### This notebook covers:\n",
    "- Modular loading of historical stock price data  \n",
    "- Basic technical indicator computation using TA-Lib  \n",
    "- Alignment of stock data with enriched sentiment signals  \n",
    "- Preparation for downstream correlation analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29917ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Working directory is now: c:\\Users\\admin\\Documents\\GIT Repositories\\b5w1-stock-market-challenge\n",
      "üìÑ Sentiment file found ‚úÖ\n",
      "‚úÖ AAPL data file: data/yfinance_data\\AAPL_historical_data.csv\n",
      "‚úÖ AMZN data file: data/yfinance_data\\AMZN_historical_data.csv\n",
      "‚úÖ GOOG data file: data/yfinance_data\\GOOG_historical_data.csv\n",
      "‚úÖ META data file: data/yfinance_data\\META_historical_data.csv\n",
      "‚úÖ MSFT data file: data/yfinance_data\\MSFT_historical_data.csv\n",
      "‚úÖ NVDA data file: data/yfinance_data\\NVDA_historical_data.csv\n",
      "‚úÖ TSLA data file: data/yfinance_data\\TSLA_historical_data.csv\n"
     ]
    }
   ],
   "source": [
    "# üóÇÔ∏è Project Directory Setup\n",
    "\n",
    "#To ensure smooth path handling across environments, we standardize the working directory and define data locations relative to the project root.\n",
    "\n",
    "#- **Sentiment Dataset**: `data/cleaned_headlines_sample.csv`\n",
    "#- **Stock Price Data**: `data/yfinance_data/*.csv`\n",
    "\n",
    "#All modules are assumed to be accessible from the `src/` folder when running the notebook from the root.\n",
    "\n",
    "# üõ† Standardize working directory\n",
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "print(\"üìÇ Working directory is now:\", os.getcwd())\n",
    "\n",
    "# üîé Confirm required sentiment and price files exist\n",
    "sentiment_file = \"data/cleaned_headlines_sample.csv\"\n",
    "price_dir = \"data/yfinance_data\"\n",
    "expected_tickers = [\"AAPL\", \"AMZN\", \"GOOG\", \"META\", \"MSFT\", \"NVDA\", \"TSLA\"]\n",
    "\n",
    "# Check sentiment file\n",
    "print(\"üìÑ Sentiment file found ‚úÖ\" if os.path.exists(sentiment_file) else f\"‚ùå Sentiment file missing: {sentiment_file}\")\n",
    "\n",
    "# Check stock price files\n",
    "for ticker in expected_tickers:\n",
    "    price_path = os.path.join(price_dir, f\"{ticker}_historical_data.csv\")\n",
    "    status = \"‚úÖ\" if os.path.exists(price_path) else \"‚ùå\"\n",
    "    print(f\"{status} {ticker} data file: {price_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0bd6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üì¶ Core Libraries\n",
    "# ------------------------------------------------------------------------------\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# üìà Financial Analysis & Signal Tools\n",
    "# ------------------------------------------------------------------------------\n",
    "# TA-Lib for technical indicators (MACD, RSI, etc.)\n",
    "import talib\n",
    "\n",
    "# For future NLP-driven sentiment joins\n",
    "from rapidfuzz import fuzz, process  # Optional: for fuzzy ticker/event joins\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# üîß Display & Notebook Config\n",
    "# ------------------------------------------------------------------------------\n",
    "from IPython.display import display\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# üõ†Ô∏è Module Reloading for Dev Iteration\n",
    "# ------------------------------------------------------------------------------\n",
    "import importlib\n",
    "import src.price_data_loader\n",
    "import src.news_loader\n",
    "\n",
    "importlib.reload(src.price_data_loader)\n",
    "importlib.reload(src.news_loader)\n",
    "\n",
    "from src.price_data_loader import PriceDataLoader\n",
    "from src.news_loader import NewsDataLoader\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# üìã Display Settings\n",
    "# ------------------------------------------------------------------------------\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a3bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üîÅ Reload custom modules for live development\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import importlib\n",
    "import src.price_data_loader\n",
    "import src.news_loader\n",
    "\n",
    "# Reload to ensure any updates to the file are picked up\n",
    "importlib.reload(src.price_data_loader)\n",
    "importlib.reload(src.news_loader)\n",
    "\n",
    "# Bring updated class definitions into scope\n",
    "from src.price_data_loader import PriceDataLoader\n",
    "from src.news_loader import NewsDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe66982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Loaded: AAPL | Path: data/yfinance_data\\AAPL_historical_data.csv\n",
      "üì¶ Encoding used: utf-8\n",
      "üî¢ Rows: 10,998 | Columns: 10\n",
      "üóìÔ∏è Date range: 1980-12-12 ‚Üí 2024-07-30\n",
      "üß™ Columns: Date, Open, High, Low, Close, Adj Close, Volume, Dividends, Stock Splits, cleaned_date\n",
      "\n",
      "\n",
      "üìÑ Loaded: AMZN | Path: data/yfinance_data\\AMZN_historical_data.csv\n",
      "üì¶ Encoding used: utf-8\n",
      "üî¢ Rows: 6,846 | Columns: 10\n",
      "üóìÔ∏è Date range: 1997-05-15 ‚Üí 2024-07-30\n",
      "üß™ Columns: Date, Open, High, Low, Close, Adj Close, Volume, Dividends, Stock Splits, cleaned_date\n",
      "\n",
      "\n",
      "üìÑ Loaded: GOOG | Path: data/yfinance_data\\GOOG_historical_data.csv\n",
      "üì¶ Encoding used: utf-8\n",
      "üî¢ Rows: 5,020 | Columns: 10\n",
      "üóìÔ∏è Date range: 2004-08-19 ‚Üí 2024-07-30\n",
      "üß™ Columns: Date, Open, High, Low, Close, Adj Close, Volume, Dividends, Stock Splits, cleaned_date\n",
      "\n",
      "\n",
      "üìÑ Loaded: META | Path: data/yfinance_data\\META_historical_data.csv\n",
      "üì¶ Encoding used: utf-8\n",
      "üî¢ Rows: 2,926 | Columns: 10\n",
      "üóìÔ∏è Date range: 2012-12-12 ‚Üí 2024-07-30\n",
      "üß™ Columns: Date, Open, High, Low, Close, Adj Close, Volume, Dividends, Stock Splits, cleaned_date\n",
      "\n",
      "\n",
      "üìÑ Loaded: MSFT | Path: data/yfinance_data\\MSFT_historical_data.csv\n",
      "üì¶ Encoding used: utf-8\n",
      "üî¢ Rows: 9,672 | Columns: 10\n",
      "üóìÔ∏è Date range: 1986-03-13 ‚Üí 2024-07-30\n",
      "üß™ Columns: Date, Open, High, Low, Close, Adj Close, Volume, Dividends, Stock Splits, cleaned_date\n",
      "\n",
      "\n",
      "üìÑ Loaded: NVDA | Path: data/yfinance_data\\NVDA_historical_data.csv\n",
      "üì¶ Encoding used: utf-8\n",
      "üî¢ Rows: 6,421 | Columns: 10\n",
      "üóìÔ∏è Date range: 1999-01-22 ‚Üí 2024-07-30\n",
      "üß™ Columns: Date, Open, High, Low, Close, Adj Close, Volume, Dividends, Stock Splits, cleaned_date\n",
      "\n",
      "\n",
      "üìÑ Loaded: TSLA | Path: data/yfinance_data\\TSLA_historical_data.csv\n",
      "üì¶ Encoding used: utf-8\n",
      "üî¢ Rows: 3,545 | Columns: 10\n",
      "üóìÔ∏è Date range: 2010-06-29 ‚Üí 2024-07-30\n",
      "üß™ Columns: Date, Open, High, Low, Close, Adj Close, Volume, Dividends, Stock Splits, cleaned_date\n",
      "\n",
      "‚úÖ All stock price files loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ File loaded: data/cleaned_headlines_sample.csv\n",
      "üì¶ Encoding used: utf-8\n",
      "üî¢ Rows: 1,407,328 | Columns: 23\n",
      "üß™ Columns: Unnamed: 0, headline, url, publisher, date, stock, cleaned_date, cleaned_headline, headline_length, word_count, publisher_domain, date_only, hour, day_of_week, is_weekend, bullish_flag, bearish_flag, vader_scores, vader_compound, vader_sentiment, textblob_polarity, ensemble_sentiment, ensemble_confidence\n",
      "\n",
      "‚úÖ Enriched sentiment dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üì• Load Stock Price Data & Enriched News Sentiment Dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from src.price_data_loader import PriceDataLoader\n",
    "from src.news_loader import NewsDataLoader  # ‚úÖ Reuse Task 1 loader\n",
    "\n",
    "# Define paths to stock price directory and sentiment CSV file\n",
    "PRICE_DATA_DIR = \"data/yfinance_data\"\n",
    "SENTIMENT_DATA_PATH = \"data/cleaned_headlines_sample.csv\"\n",
    "\n",
    "# Initialize and load all stock price CSVs in the directory\n",
    "try:\n",
    "    price_loader = PriceDataLoader(\n",
    "        folder_path=PRICE_DATA_DIR, verbose=True\n",
    "    )  # ‚úÖ Correct param\n",
    "    prices_df = price_loader.load_all()\n",
    "    print(\"‚úÖ All stock price files loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load stock price data: {e}\")\n",
    "    prices_df = None  # gracefully degrade\n",
    "\n",
    "# Initialize and load the enriched sentiment dataset\n",
    "try:\n",
    "    sentiment_loader = NewsDataLoader(\n",
    "        path=SENTIMENT_DATA_PATH, parse_dates=[\"cleaned_date\"], verbose=True\n",
    "    )\n",
    "    sentiment_df = sentiment_loader.load()\n",
    "    print(\"‚úÖ Enriched sentiment dataset loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load sentiment dataset: {e}\")\n",
    "    sentiment_df = None  # gracefully degrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25aa9ef",
   "metadata": {},
   "source": [
    "## ‚úÖ Initial Sanity Checks ‚Äì Structure, Missingness, Duplicates\n",
    "\n",
    "Before diving into analysis, we run a quick diagnostic to verify data health:\n",
    "\n",
    "- Preview the top 3 rows for structural validation.\n",
    "- Print full column data types to confirm schema expectations.\n",
    "- Check for missing values across all columns.\n",
    "- Identify and count any fully duplicated rows.\n",
    "\n",
    "These checks help detect formatting issues or corrupt entries early, ensuring downstream feature engineering operates on clean and consistent data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d4a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Sanity Check ‚Äì Stock Price Data\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "High",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Adj Close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dividends",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Stock Splits",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cleaned_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "ticker",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "961b0759-293a-4e28-8d02-0df6cf35aee8",
       "rows": [
        [
         "0",
         "1980-12-12",
         "0.1283479928970337",
         "0.1289059966802597",
         "0.1283479928970337",
         "0.1283479928970337",
         "0.098943218588829",
         "469033600",
         "0.0",
         "0.0",
         "1980-12-12 00:00:00",
         "AAPL"
        ],
        [
         "1",
         "1980-12-15",
         "0.1222100034356117",
         "0.1222100034356117",
         "0.1216519996523857",
         "0.1216519996523857",
         "0.093781292438507",
         "175884800",
         "0.0",
         "0.0",
         "1980-12-15 00:00:00",
         "AAPL"
        ],
        [
         "2",
         "1980-12-16",
         "0.1132809966802597",
         "0.1132809966802597",
         "0.1127230003476142",
         "0.1127230003476142",
         "0.0868979692459106",
         "105728000",
         "0.0",
         "0.0",
         "1980-12-16 00:00:00",
         "AAPL"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>cleaned_date</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.098943</td>\n",
       "      <td>469033600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.093781</td>\n",
       "      <td>175884800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.086898</td>\n",
       "      <td>105728000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close     Volume  Dividends  Stock Splits cleaned_date  \\\n",
       "0  1980-12-12  0.128348  0.128906  0.128348  0.128348   0.098943  469033600        0.0           0.0   1980-12-12   \n",
       "1  1980-12-15  0.122210  0.122210  0.121652  0.121652   0.093781  175884800        0.0           0.0   1980-12-15   \n",
       "2  1980-12-16  0.113281  0.113281  0.112723  0.112723   0.086898  105728000        0.0           0.0   1980-12-16   \n",
       "\n",
       "  ticker  \n",
       "0   AAPL  \n",
       "1   AAPL  \n",
       "2   AAPL  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Column Data Types:\n",
      "Date                    object\n",
      "Open                   float64\n",
      "High                   float64\n",
      "Low                    float64\n",
      "Close                  float64\n",
      "Adj Close              float64\n",
      "Volume                   int64\n",
      "Dividends              float64\n",
      "Stock Splits           float64\n",
      "cleaned_date    datetime64[ns]\n",
      "ticker                  object\n",
      "dtype: object\n",
      "\n",
      "üîç Missing Value Summary:\n",
      "‚úÖ No missing values detected.\n",
      "‚úÖ No duplicate rows found.\n",
      "\n",
      "üß™ Sanity Check ‚Äì Enriched Sentiment Data\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "headline",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "publisher",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stock",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cleaned_date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "cleaned_headline",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "headline_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "publisher_domain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date_only",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_of_week",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_weekend",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "bullish_flag",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "bearish_flag",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "vader_scores",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "vader_compound",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vader_sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "textblob_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ensemble_sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ensemble_confidence",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "abd3f15b-a2bd-4e51-882b-b1cb88f015c3",
       "rows": [
        [
         "0",
         "0",
         "Stocks That Hit 52-Week Highs On Friday",
         "https://www.benzinga.com/news/20/06/16190091/stocks-that-hit-52-week-highs-on-friday",
         "Benzinga Insights",
         "2020-06-05 10:30:54-04:00",
         "A",
         "2020-06-05 00:00:00",
         "stocks hit 52week highs friday",
         "39",
         "7",
         "benzinga.com",
         "2020-06-04",
         "20",
         "Thursday",
         "False",
         "True",
         "False",
         "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}",
         "0.0",
         "neutral",
         "0.0",
         "neutral",
         "0.5"
        ],
        [
         "1",
         "1",
         "Stocks That Hit 52-Week Highs On Wednesday",
         "https://www.benzinga.com/news/20/06/16170189/stocks-that-hit-52-week-highs-on-wednesday",
         "Benzinga Insights",
         "2020-06-03 10:45:20-04:00",
         "A",
         "2020-06-03 00:00:00",
         "stocks hit 52week highs wednesday",
         "42",
         "7",
         "benzinga.com",
         "2020-06-02",
         "20",
         "Tuesday",
         "False",
         "True",
         "False",
         "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}",
         "0.0",
         "neutral",
         "0.0",
         "neutral",
         "0.5"
        ],
        [
         "2",
         "2",
         "71 Biggest Movers From Friday",
         "https://www.benzinga.com/news/20/05/16103463/71-biggest-movers-from-friday",
         "Lisa Levin",
         "2020-05-26 04:30:07-04:00",
         "A",
         "2020-05-26 00:00:00",
         "71 biggest movers friday",
         "29",
         "5",
         "benzinga.com",
         "2020-05-25",
         "20",
         "Monday",
         "False",
         "False",
         "False",
         "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}",
         "0.0",
         "neutral",
         "0.0",
         "neutral",
         "0.5"
        ]
       ],
       "shape": {
        "columns": 23,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>cleaned_date</th>\n",
       "      <th>cleaned_headline</th>\n",
       "      <th>headline_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>publisher_domain</th>\n",
       "      <th>date_only</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>bullish_flag</th>\n",
       "      <th>bearish_flag</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>ensemble_sentiment</th>\n",
       "      <th>ensemble_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>stocks hit 52week highs friday</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>benzinga.com</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>20</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>stocks hit 52week highs wednesday</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>benzinga.com</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>20</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>71 biggest movers friday</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>benzinga.com</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>20</td>\n",
       "      <td>Monday</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    headline                                                url  \\\n",
       "0           0     Stocks That Hit 52-Week Highs On Friday  https://www.benzinga.com/news/20/06/16190091/s...   \n",
       "1           1  Stocks That Hit 52-Week Highs On Wednesday  https://www.benzinga.com/news/20/06/16170189/s...   \n",
       "2           2               71 Biggest Movers From Friday  https://www.benzinga.com/news/20/05/16103463/7...   \n",
       "\n",
       "           publisher                       date stock cleaned_date                   cleaned_headline  \\\n",
       "0  Benzinga Insights  2020-06-05 10:30:54-04:00     A   2020-06-05     stocks hit 52week highs friday   \n",
       "1  Benzinga Insights  2020-06-03 10:45:20-04:00     A   2020-06-03  stocks hit 52week highs wednesday   \n",
       "2         Lisa Levin  2020-05-26 04:30:07-04:00     A   2020-05-26           71 biggest movers friday   \n",
       "\n",
       "   headline_length  word_count publisher_domain   date_only  hour day_of_week  is_weekend  bullish_flag  bearish_flag  \\\n",
       "0               39           7     benzinga.com  2020-06-04    20    Thursday       False          True         False   \n",
       "1               42           7     benzinga.com  2020-06-02    20     Tuesday       False          True         False   \n",
       "2               29           5     benzinga.com  2020-05-25    20      Monday       False         False         False   \n",
       "\n",
       "                                        vader_scores  vader_compound vader_sentiment  textblob_polarity  \\\n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...             0.0         neutral                0.0   \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...             0.0         neutral                0.0   \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...             0.0         neutral                0.0   \n",
       "\n",
       "  ensemble_sentiment  ensemble_confidence  \n",
       "0            neutral                  0.5  \n",
       "1            neutral                  0.5  \n",
       "2            neutral                  0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Column Data Types:\n",
      "Unnamed: 0                      int64\n",
      "headline                       object\n",
      "url                            object\n",
      "publisher                      object\n",
      "date                           object\n",
      "stock                          object\n",
      "cleaned_date           datetime64[ns]\n",
      "cleaned_headline               object\n",
      "headline_length                 int64\n",
      "word_count                      int64\n",
      "publisher_domain               object\n",
      "date_only                      object\n",
      "hour                            int64\n",
      "day_of_week                    object\n",
      "is_weekend                       bool\n",
      "bullish_flag                     bool\n",
      "bearish_flag                     bool\n",
      "vader_scores                   object\n",
      "vader_compound                float64\n",
      "vader_sentiment                object\n",
      "textblob_polarity             float64\n",
      "ensemble_sentiment             object\n",
      "ensemble_confidence           float64\n",
      "dtype: object\n",
      "\n",
      "üîç Missing Value Summary:\n",
      "cleaned_headline    2\n",
      "dtype: int64\n",
      "‚úÖ No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# ‚úÖ Initial Sanity Check ‚Äì Stock Price and Sentiment Datasets\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def run_sanity_check(df, name=\"DataFrame\"):\n",
    "    \"\"\"\n",
    "    Runs basic data quality checks on a given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to check.\n",
    "    name : str\n",
    "        A label for the dataset (used in printouts).\n",
    "    \"\"\"\n",
    "    print(f\"\\nüß™ Sanity Check ‚Äì {name}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    if df is not None:\n",
    "        # Show preview\n",
    "        display(df.head(3))\n",
    "\n",
    "        # Column types\n",
    "        print(\"üß¨ Column Data Types:\")\n",
    "        print(df.dtypes)\n",
    "\n",
    "        # Nulls\n",
    "        print(\"\\nüîç Missing Value Summary:\")\n",
    "        missing = df.isna().sum()\n",
    "        print(\n",
    "            missing[missing > 0] if missing.any() else \"‚úÖ No missing values detected.\"\n",
    "        )\n",
    "\n",
    "        # Duplicates\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        if duplicate_count > 0:\n",
    "            print(f\"‚ö†Ô∏è Found {duplicate_count:,} duplicate rows.\")\n",
    "        else:\n",
    "            print(\"‚úÖ No duplicate rows found.\")\n",
    "    else:\n",
    "        print(f\"üö´ Skipping {name} ‚Äì DataFrame not loaded.\")\n",
    "\n",
    "\n",
    "# Run checks for both datasets\n",
    "run_sanity_check(prices_df, name=\"Stock Price Data\")\n",
    "run_sanity_check(sentiment_df, name=\"Enriched Sentiment Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38efa7",
   "metadata": {},
   "source": [
    "# üîó Sentiment‚ÄìPrice Signal Alignment\n",
    "\n",
    "This section performs a robust alignment between financial news sentiment signals and historical stock price data. The alignment pipeline includes:\n",
    "\n",
    "### üßÆ Key Logic:\n",
    "\n",
    "- **Sentiment Encoding**: Converts `ensemble_sentiment` (bullish, neutral, bearish) into a normalized numerical score in the range [-1, 1].\n",
    "\n",
    "- **Exponential Time Decay**: When multiple headlines occur on the same day for a stock, sentiment signals are weighted using an **exponential decay function**, prioritizing more recent headlines. The decay factor (Œª) controls how aggressively past signals are discounted.\n",
    "\n",
    "- **Return Computation**:\n",
    "  - `return_t`: Daily percentage change in closing prices.\n",
    "  - `return_t+1`: Forward return for next-day modeling tasks.\n",
    "\n",
    "- **Final Merge**: Sentiment and return data are joined on both `ticker` and `cleaned_date`, producing a rich dataset for correlation analysis or signal evaluation.\n",
    "\n",
    "### üì¶ Output:\n",
    "A merged DataFrame containing:\n",
    "- `ticker`, `cleaned_date`\n",
    "- OHLCV price data (`Open`, `Close`, etc.)\n",
    "- `weighted_sentiment` (decayed score)\n",
    "- `return_t`, `return_t+1` (realized returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cf3d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sentiment labels converted to numeric scale [-1, 0, 1]\n",
      "üìâ Exponential decay applied with Œª = 0.7\n",
      "üìà Returns computed: current (t), forward (t+1)\n",
      "‚ùå Failed to align sentiment and price data: 'ticker'\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üßæ Standardize sentiment_df for alignment\n",
    "# ------------------------------------------------------------------------------\n",
    "# Rename 'stock' column to 'ticker' for consistency with price_df\n",
    "sentiment_df.rename(columns={\"stock\": \"ticker\"}, inplace=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# üîó Align Enriched Sentiment with Price Data using Exponential Decay\n",
    "# ------------------------------------------------------------------------------\n",
    "from src.sentiment_return_aligner import SentimentReturnAligner\n",
    "\n",
    "try:\n",
    "    # Initialize the aligner with decay factor and verbosity\n",
    "    aligner = SentimentReturnAligner(\n",
    "        price_df=prices_df,\n",
    "        sentiment_df=sentiment_df,\n",
    "        decay_lambda=0.7,  # Strong exponential decay\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Run alignment process to merge and enrich sentiment‚Äìprice dataset\n",
    "    aligned_df = aligner.align()\n",
    "\n",
    "    # Show preview of final merged dataset\n",
    "    display(aligned_df.head(5))\n",
    "    print(\"‚úÖ Sentiment and return data successfully aligned.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to align sentiment and price data: {e}\")\n",
    "    aligned_df = None  # fallback in case of error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8be0d",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------\n",
    "üìê Technical Indicators ‚Äì RSI, MACD, ATR, SMA, EMA\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "We now extend the sentiment‚Äìreturn aligned dataset with core technical indicators using **TA-Lib**.\n",
    "\n",
    "Indicators added:\n",
    "- **SMA (14-day)** ‚Äì Simple moving average\n",
    "- **EMA (14-day)** ‚Äì Exponential moving average\n",
    "- **RSI (14-day)** ‚Äì Relative strength index\n",
    "- **MACD** and **MACD signal** ‚Äì Momentum indicators\n",
    "- **ATR (14-day)** ‚Äì Average true range (volatility)\n",
    "\n",
    "These indicators support downstream predictive modeling and correlation testing by capturing trend, momentum, and volatility patterns for each stock.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "192d56fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Failed to compute technical indicators: 'NoneType' object has no attribute 'copy'\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üßÆ Compute Technical Indicators on Aligned Dataset\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from src.technical_indicator_calculator import TechnicalIndicatorCalculator\n",
    "\n",
    "try:\n",
    "    # Initialize indicator engine\n",
    "    indicator_calc = TechnicalIndicatorCalculator(\n",
    "        df=aligned_df,\n",
    "        ticker_col=\"ticker\",\n",
    "        date_col=\"cleaned_date\",\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Add RSI, SMA, EMA, MACD, ATR\n",
    "    enriched_df = indicator_calc.add_indicators()\n",
    "\n",
    "    # Show result sample\n",
    "    display(enriched_df.head(5))\n",
    "    print(\"‚úÖ Technical indicators computed and added.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to compute technical indicators: {e}\")\n",
    "    enriched_df = None  # fallback in case of failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8892ea6",
   "metadata": {},
   "source": [
    "# üìà Signal Visual Diagnostics\n",
    "\n",
    "This section visualizes the relationship between sentiment scores, stock price movements, and technical indicators for exploratory signal analysis. It includes:\n",
    "\n",
    "- üß† **Sentiment vs. Price Trends**: Track weighted sentiment overlays on adjusted closing prices.\n",
    "- üéØ **Sentiment‚ÄìReturn Scatter**: Examine correlation between sentiment and next-day returns.\n",
    "- üõ†Ô∏è **Technical Indicators**: Plot SMA, EMA, RSI, and MACD per ticker.\n",
    "\n",
    "Use this to validate signal strength, detect lags, and identify alignment with market behaviors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4960e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# üìä Visualize Signals for Diagnostic Insights\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from src.signal_visualizer import SignalVisualizer\n",
    "\n",
    "# Initialize the visualizer with the enriched dataset\n",
    "visualizer = SignalVisualizer(df=enriched_df)\n",
    "\n",
    "# Choose a stock ticker to analyze (example: \"AAPL\", \"GOOG\", etc.)\n",
    "selected_ticker = \"AAPL\"\n",
    "\n",
    "# Plot sentiment vs. price\n",
    "visualizer.plot_sentiment_vs_price(ticker=selected_ticker)\n",
    "\n",
    "# Plot scatter of sentiment vs. next-day return\n",
    "visualizer.plot_sentiment_return_scatter(ticker=selected_ticker)\n",
    "\n",
    "# Plot technical indicators (SMA, EMA, RSI, MACD)\n",
    "visualizer.plot_technical_indicators(ticker=selected_ticker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-market-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
